import pdb
import random
import math
import copy

import pandas as pd
import numpy as np
import torch

from torch.utils.data import Dataset


class oneDataSet(Dataset):
    def __init__(self):
        self.x = torch.tensor([[-0.4545, -0.3382,  0.5685, -0.6863, -0.6523,  0.0227, -0.2503, -0.3209,
         -0.3960, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6171,  0.7012, -0.6033, -0.5126, -0.1852, -0.4033, -0.2067,
         -0.6697, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6578,  0.6321, -0.7952, -0.6351, -0.0824, -0.1054, -0.1733,
         -0.7133, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6930,  0.7493, -0.7630, -0.7008, -0.3206, -0.3258, -0.6463,
         -0.2850, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6973,  0.6145, -0.7550, -0.8116, -0.3238, -0.0819, -0.5358,
         -0.4066, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5829,  0.6020, -0.8212, -0.8588, -0.1818,  0.0596, -0.4972,
         -0.5056, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5963,  0.6147, -0.8518, -0.6514, -0.1551, -0.4113, -0.3679,
         -0.3650, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6277,  0.4940, -0.7142, -0.7122,  0.1208,  0.0615, -0.3059,
         -0.3420, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5792,  0.4142, -0.5927, -0.5835,  0.3918, -0.0549, -0.4006,
         -0.5185, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5243,  0.4638, -0.6789, -0.4329,  0.2427, -0.3700, -0.3672,
         -0.4794, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7818,  0.2988, -0.6450, -0.7888, -0.2402, -0.4587, -0.5918,
         -0.5275, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6562,  0.5898, -0.7177, -0.7616, -0.3989, -0.4074, -0.6455,
         -0.5577, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5463,  0.7126, -0.7474, -0.6887, -0.4757, -0.3794, -0.5940,
         -0.5950, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5441,  0.6020, -0.7569, -0.7142, -0.3061, -0.0991, -0.5249,
         -0.2643, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6524,  0.6461, -0.6321, -0.6437, -0.0080,  0.1938, -0.6339,
         -0.3547, -1.0000,  0.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6754,  0.6228, -0.6784, -0.7447,  0.0388, -0.3523, -0.6301,
         -0.3121, -1.0000,  0.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6524,  0.6142, -0.6778, -0.6591, -0.2520, -0.4883, -0.3960,
         -0.4744, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6643,  0.7175, -0.7689, -0.6109, -0.4616, -0.2413, -0.3230,
         -0.5147, -1.0000,  0.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5756,  0.5578, -0.8610, -0.7503, -0.0687, -0.4111, -0.4412,
         -0.1849, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5480,  0.4725, -0.7825, -0.6564, -0.4170, -0.3867, -0.4659,
         -0.2525, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5570,  0.7473, -0.6433, -0.3225, -0.4747, -0.3335, -0.5201,
         -0.0336, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6100,  0.6882, -0.6731,  0.0250, -0.2586, -0.2084, -0.3550,
         -0.5941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.3916,  0.6477, -0.6849,  0.0400, -0.1960, -0.3792, -0.2883,
         -0.4493, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4542,  0.5808, -0.5955, -0.2171, -0.1191, -0.3724, -0.3935,
         -0.0247, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5254,  0.5406, -0.6388, -0.6163, -0.1780, -0.0860, -0.6671,
         -0.3027, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6788,  0.6622, -0.5626, -0.6125, -0.1253, -0.4629, -0.5310,
         -0.5065, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7285,  0.7164, -0.7645, -0.5616,  0.1019, -0.5410, -0.4606,
         -0.4741, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6301,  0.6354, -0.7126, -0.5748, -0.0973, -0.4235, -0.5330,
         -0.4996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5767,  0.5491, -0.6997, -0.7001, -0.2388, -0.1525, -0.3113,
         -0.5781, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6148,  0.2157, -0.7321, -0.7286, -0.1849,  0.1590, -0.2402,
         -0.3062, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5204, -0.1491, -0.6761, -0.6008, -0.1911, -0.2153, -0.0819,
          0.0060, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4550, -0.0370, -0.8133,  0.0072, -0.1338, -0.4449, -0.2633,
          0.1366, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6451,  0.1150, -0.7239,  0.2348, -0.4244,  0.0228, -0.1802,
         -0.1671, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6721,  0.3472, -0.6940,  0.1325, -0.0625,  0.0777, -0.1188,
         -0.3388, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7261,  0.4522, -0.6935, -0.1932, -0.0628, -0.2236, -0.3585,
          0.3139, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.8265,  0.5711, -0.6046, -0.6008,  0.1112, -0.4933, -0.5965,
         -0.4807, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.8509,  0.5463, -0.6563, -0.6617,  0.1254, -0.2778, -0.6674,
         -0.5901, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4806,  0.5614, -0.8104, -0.6195, -0.1642, -0.3126, -0.5657,
         -0.5022, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4844,  0.6594, -0.7687, -0.7410,  0.0809, -0.3208, -0.6441,
         -0.2658, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5967,  0.5944, -0.7637, -0.7382, -0.2791, -0.0668, -0.6494,
         -0.2600, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5442,  0.5467, -0.7518, -0.6122, -0.5718,  0.1278, -0.6321,
         -0.4253, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.3881,  0.5425, -0.7014, -0.7754, -0.4756, -0.1751, -0.3199,
         -0.4662, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5564,  0.5317, -0.7502, -0.6440, -0.2843, -0.4520, -0.6183,
         -0.4328, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7389,  0.5521, -0.7462, -0.5512, -0.1400, -0.3010, -0.3633,
         -0.5727, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5563,  0.4825, -0.7893, -0.6633, -0.3745, -0.3112, -0.5726,
         -0.5801, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5157,  0.6204, -0.6947, -0.8026, -0.0692, -0.2751, -0.3948,
         -0.6518, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7801,  0.4700, -0.6560, -0.8050, -0.1325, -0.2226, -0.2907,
         -0.5297, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7935,  0.3372, -0.7763, -0.6446, -0.3693, -0.2418, -0.4567,
         -0.4816, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6241,  0.4209, -0.6575, -0.6695, -0.1709, -0.2372, -0.1504,
         -0.3451, -1.0000, -1.0000, -1.0000, -1.0000,  0.0000,  1.0000, -0.9000],
        [-0.4545, -0.5985,  0.6049, -0.7467, -0.6914,  0.0291, -0.1841, -0.2917,
         -0.1741, -1.0000, -1.0000, -1.0000, -1.0000,  0.0000,  1.0000, -0.9000],
        [-0.4545, -0.6717,  0.7007, -0.7821, -0.5626, -0.0010, -0.4253, -0.3019,
         -0.5104, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7190,  0.5429, -0.7737, -0.6798, -0.1339, -0.6038, -0.4894,
         -0.6712, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7181,  0.5969, -0.7690, -0.5887, -0.1313, -0.5946, -0.4758,
         -0.6189, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6980,  0.6087, -0.7025, -0.5730, -0.0862, -0.0456, -0.5721,
         -0.5153, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4767,  0.6355, -0.6616, -0.7228, -0.2803, -0.2557, -0.6505,
         -0.4721, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.3651,  0.5585, -0.7235, -0.6233, -0.4180, -0.2766, -0.4747,
         -0.5420, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.1155,  0.4456, -0.7585, -0.6493, -0.3216, -0.1468, -0.4781,
         -0.5472, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545,  0.0039,  0.5660, -0.7733, -0.6461, -0.1187, -0.0468, -0.2651,
         -0.3827, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545,  0.0944,  0.5125, -0.8398, -0.5436, -0.2861, -0.1219, -0.3608,
         -0.5038, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.2683,  0.4817, -0.6499, -0.5523, -0.1673, -0.2929, -0.4388,
         -0.7547, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6324,  0.5669, -0.6159, -0.6986, -0.2166, -0.1911, -0.4528,
         -0.3859, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5484,  0.6281, -0.8192, -0.3634, -0.1430, -0.2395, -0.5459,
         -0.1613, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6517,  0.3989, -0.8044, -0.7400, -0.3988, -0.5640, -0.5682,
         -0.1959, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6951,  0.4929, -0.7241, -0.9521, -0.0996, -0.4971, -0.4675,
         -0.4097, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5848,  0.6780, -0.6551, -0.8010, -0.2708, -0.2319, -0.5293,
         -0.2921, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6205,  0.6526, -0.6690, -0.7614, -0.2888, -0.2141, -0.4578,
         -0.3780, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6483,  0.6519, -0.7557, -0.7394, -0.3383, -0.4934, -0.3591,
         -0.4821, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6841,  0.6174, -0.7654, -0.6679, -0.6496, -0.3151, -0.4443,
         -0.4259, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5822,  0.5366, -0.7737, -0.5183, -0.6265, -0.3409, -0.6830,
         -0.4127, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4145,  0.6962, -0.7027, -0.5989, -0.6008, -0.3064, -0.6843,
         -0.2050, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4579,  0.7058, -0.7066, -0.6106, -0.4954, -0.4836, -0.6992,
         -0.1906, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6015,  0.6463, -0.6690, -0.5753, -0.0597, -0.6909, -0.3918,
         -0.5383, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6242,  0.5959, -0.6781, -0.6937,  0.1101, -0.3287, -0.5591,
         -0.4574, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.8026,  0.6363, -0.6742, -0.5533,  0.1130, -0.4441, -0.7052,
         -0.4412, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6644,  0.5825, -0.7424, -0.5655, -0.0712, -0.4914, -0.6843,
         -0.6509, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5968,  0.7208, -0.6979, -0.6956, -0.3551, -0.4655, -0.2408,
         -0.4544, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6629,  0.6129, -0.8078, -0.7143, -0.5236, -0.2106, -0.3611,
         -0.5523, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5252,  0.5378, -0.7519, -0.6163, -0.4643, -0.3247, -0.4890,
         -0.3566, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.3531,  0.5552, -0.7739, -0.6648, -0.3932, -0.5309, -0.4688,
         -0.3978, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4975,  0.7224, -0.7972, -0.6604, -0.1345, -0.5718, -0.2201,
         -0.5251, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6687,  0.6305, -0.7013, -0.5988, -0.2620, -0.3994, -0.2253,
         -0.2375, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.8660,  0.6372, -0.7929, -0.1246, -0.1236, -0.3000, -0.6419,
          0.1407,  0.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6398,  0.6003, -0.7181,  0.2022,  0.2009, -0.1262, -0.5297,
         -0.6191, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5580,  0.6561, -0.7327,  0.1748, -0.4360, -0.4313, -0.2361,
         -0.5268, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6536,  0.7555, -0.6517, -0.3421, -0.6822, -0.4095, -0.1438,
          0.2783, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6466,  0.6155, -0.7109, -0.6771, -0.2488, -0.6084, -0.2472,
         -0.2623, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5888,  0.6212, -0.7265, -0.5202, -0.2748, -0.6398, -0.3355,
         -0.5041, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5668,  0.6974, -0.6706, -0.5099, -0.8638, -0.2833, -0.5397,
         -0.3141, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5570,  0.7078, -0.6272, -0.6253, -0.6426, -0.2777, -0.3273,
         -0.4111, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5221,  0.8566, -0.7173, -0.6862, -0.4712, -0.0652, -0.3455,
         -0.3373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5656,  0.8292, -0.6392, -0.8220, -0.1328, -0.2290, -0.4647,
         -0.3276, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5126,  0.6526, -0.6320, -0.6273, -0.2979, -0.3473, -0.0667,
         -0.4437, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6523,  0.5357, -0.1058, -0.7135, -0.5815, -0.4059,  0.3136,
         -0.5537, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5383,  0.4555,  0.1956, -0.6949, -0.1131, -0.0423, -0.0989,
         -0.3796, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6112,  0.6633,  0.1947, -0.6773, -0.0780,  0.2147, -0.4692,
         -0.7426, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6709,  0.5968, -0.3355, -0.7384, -0.2649, -0.1207,  0.3484,
         -0.6559, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5464,  0.4022, -0.7975, -0.6866, -0.1452, -0.2080, -0.4776,
         -0.7446, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6447,  0.4823, -0.7583, -0.6985, -0.1852, -0.1848, -0.4264,
         -0.5451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5083,  0.6786, -0.7513, -0.6288, -0.1533, -0.4088, -0.4315,
         -0.5479, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4240,  0.6552, -0.7096, -0.7092, -0.3106, -0.4067, -0.7649,
         -0.4120, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6289,  0.5094, -0.7690, -0.6652, -0.5307, -0.0103, -0.6185,
         -0.2498, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6032,  0.4860, -0.6379, -0.5779, -0.0581,  0.1741, -0.4851,
         -0.5109, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6742,  0.4754, -0.6010, -0.6287,  0.1471, -0.1168, -0.3058,
         -0.5365, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6506,  0.4602, -0.6798, -0.6865,  0.1395, -0.1291, -0.5816,
         -0.4965, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7305,  0.6244, -0.5582, -0.7066,  0.0174, -0.4827, -0.3284,
         -0.7027, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6855,  0.7033, -0.6664, -0.7070, -0.2828, -0.6278, -0.4060,
         -0.6489, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5585,  0.5623, -0.7417, -0.6429, -0.5625, -0.2167, -0.4223,
         -0.2403, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5412,  0.4517, -0.7618, -0.6250, -0.1507,  0.1074, -0.2988,
         -0.4648, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4931,  0.3788, -0.7698, -0.7539, -0.5098, -0.0143, -0.1915,
         -0.6098, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5642,  0.4710, -0.7392, -0.6578, -0.4440, -0.4920, -0.3312,
         -0.2815, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5955,  0.6075, -0.7310, -0.6418, -0.5884,  0.0141, -0.1937,
         -0.2724, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6146,  0.6899, -0.6710, -0.7826, -0.5667, -0.2555, -0.2622,
         -0.4761, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6571,  0.6027, -0.7595, -0.7784, -0.4201, -0.5311, -0.2797,
         -0.6492, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6503,  0.5156, -0.7451, -0.6604, -0.4632, -0.1129, -0.3801,
         -0.3658, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7269,  0.4682, -0.5763, -0.6298, -0.2575, -0.3112, -0.6713,
         -0.3074, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6353,  0.5917, -0.6833, -0.7249, -0.0528,  0.0423, -0.5357,
         -0.3187, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4325,  0.5190, -0.6526, -0.6486, -0.2185, -0.4711, -0.4694,
         -0.2752, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6503,  0.5901, -0.5715, -0.5256,  0.1930, -0.1377, -0.7175,
         -0.3401, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5497,  0.6101, -0.6883, -0.6067,  0.2534, -0.3262, -0.4185,
         -0.4262, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.1795,  0.6285, -0.7497, -0.6864,  0.1707, -0.2177, -0.1193,
         -0.6313, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.0193,  0.5228, -0.7255, -0.6557, -0.1484, -0.1230, -0.1520,
         -0.3095, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545,  0.0686,  0.4682, -0.7786, -0.5457, -0.5630, -0.1272, -0.5036,
         -0.3897, -1.0000,  0.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.0927,  0.5200, -0.6177, -0.5412, -0.5042, -0.3377, -0.4842,
         -0.5707, -1.0000,  0.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4681,  0.4167, -0.6667, -0.6101, -0.1016, -0.4015, -0.3533,
         -0.1583, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.4592,  0.5302, -0.8212, -0.7122, -0.4309, -0.0109, -0.4512,
         -0.3006, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6373,  0.6111, -0.7395, -0.7705, -0.3110, -0.0058, -0.4700,
         -0.4653, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.7161,  0.5984, -0.7122, -0.7425, -0.1915, -0.0999, -0.6304,
         -0.4375, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.5764,  0.5011, -0.7112, -0.8045, -0.0713, -0.0295, -0.4763,
         -0.5570, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000],
        [-0.4545, -0.6134,  0.5960, -0.7019, -0.8213, -0.1654,  0.0262, -0.4376,
         -0.7027, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -0.9000]])
        self.y = torch.tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1.])

    def __len__(self):
        return 1

    def __getitem__(self, index):
        return self.x, self.x.shape[0], self.y


class oneTestDataSet(Dataset):
    def __init__(self):
        self.x = torch.tensor([[ 64.0000, 166.1570, 435.1805,  99.4691,  49.3987,  11.7345,  46.4358,
          11.1850,   6.1365,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 169.2729, 455.0543, 101.7963,  43.5980,  15.0679,  33.0537,
           8.5274,   6.3410,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 180.9845, 458.6172, 104.8439,  37.7135,  17.7729,  43.8420,
           7.2597,   4.0431,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 186.8130, 452.9316, 101.7568,  39.1036,  11.6331,  45.6063,
           8.0580,   5.2544,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 187.9166, 445.2609, 100.8255,  40.5045,  11.8032,  51.4123,
          10.6717,   4.7887,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 176.9078, 443.4432, 100.7043,  42.2186,  21.2646,  53.8711,
          10.6379,   3.8256,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 165.0285, 454.6240,  95.9471,  42.3635,  15.5592,  51.1011,
           8.5296,   4.0968,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.0732, 453.3026, 100.7527,  40.2547,  16.7308,  46.3300,
           8.4128,   6.4104,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 171.5777, 438.1075, 101.2121,  40.0609,  13.0677,  51.8599,
           9.7093,   6.4192,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 169.0843, 442.7453, 102.5299,  39.2725,  13.1299,  50.0673,
          11.3209,   6.2903,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 169.0100, 444.1766, 117.4165,  39.0545,  15.3500,  34.3996,
          17.1000,   5.9758,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 178.3636, 458.0390, 127.3222,  40.1914,  20.1497,  41.1017,
          10.4892,   4.0764,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 193.5185, 454.0294, 127.7908,  41.0143,  16.0637,  51.4735,
          12.0981,   5.4150,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 190.3082, 461.6832, 117.2951,  39.8614,  15.1030,  44.5033,
          18.1854,   5.7063,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 186.7785, 477.5099, 103.5728,  39.3353,  14.1990,  52.5002,
          11.5411,   5.7148,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 177.6206, 461.4356, 102.8453,  38.7882,  14.1908,  48.0726,
          10.8190,   4.9356,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.9640, 454.7909, 100.2645,  40.4084,  15.0379,  49.7954,
           8.6362,   4.8416,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 170.3448, 461.8144,  99.5376,  41.5965,  18.6551,  48.4113,
           7.9842,   4.9357,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 168.0723, 466.0305,  98.9527,  39.5643,  15.6645,  39.1369,
           8.5925,   5.4321,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.5492, 453.1459, 101.4269,  39.3990,  13.7224,  42.6261,
           9.1322,   6.1219,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 169.7949, 459.3355, 103.4274,  40.3974,  14.7314,  44.0171,
          10.2515,   5.4326,   0.0000,   0.0000,   0.0000,   1.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 170.0645, 449.6993,  99.0742,  41.2220,  13.6388,  51.6688,
          11.9270,   5.5790,   0.0000,   0.0000,   0.0000,   1.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.2083, 424.3209,  96.1474,  42.9918,  14.3480,  53.8392,
          11.6754,   5.1316,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 168.7526, 440.8732,  97.0190,  41.4883,  14.7182,  56.1415,
          13.1868,   4.2619,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 168.1060, 455.2525, 101.1969,  39.0846,  13.7165,  49.7731,
          11.3728,   4.5593,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.2639, 457.5756, 104.0011,  38.2094,  12.2146,  46.5716,
          10.3241,   4.8502,   1.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 170.6735, 450.6238,  98.9803,  40.0937,  16.6049,  48.7365,
          11.1818,   5.1078,   1.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.5993, 448.0486, 102.3992,  40.1974,  16.5713,  54.4383,
           8.9189,   6.6353,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 169.9497, 443.1553, 100.6784,  40.7384,  13.8390,  45.8458,
           9.7824,   6.0093,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.8874, 454.1471,  99.7306,  41.1230,  16.3509,  48.7405,
           9.0210,   5.3996,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 173.3370, 451.1101,  99.4988,  39.2996,  10.1139,  57.6817,
           8.8525,   5.0293,   0.0000,   0.0000,   2.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.2560, 461.9857,  99.7657,  39.5247,  15.4315,  55.2962,
           8.3041,   5.9843,   0.0000,   0.0000,   1.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.1677, 452.4905,  99.2671,  39.9953,  14.2511,  67.3886,
           7.6691,   4.4596,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 168.7222, 439.3833,  99.8449,  39.1351,  14.4004,  67.6775,
           6.9283,   4.4595,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 171.9818, 428.3221, 101.2793,  39.1215,  16.3382,  63.8926,
           8.1611,   4.4835,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 167.2818, 459.7372, 101.7952,  39.1702,  17.6849,  49.9343,
           8.9966,   3.8983,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 166.3524, 470.0327, 100.5985,  39.4812,  13.6378,  49.0610,
           9.6720,   5.9016,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 175.7605, 444.9306,  99.4642,  38.6593,  12.0171,  49.2331,
           8.9452,   6.8942,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 177.5225, 430.8696, 103.3169,  39.8324,  13.7113,  48.9586,
           8.4661,   5.3480,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 174.0370, 443.8607, 102.0728,  39.8380,  13.5517,  54.6824,
           8.6971,   5.2297,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 173.6347, 445.9387, 100.1877,  39.7332,  16.7571,  49.0424,
          10.4209,   5.1067,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 174.7076, 432.6806,  97.6052,  37.4668,  13.7433,  33.1908,
           8.9492,   6.5232,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 171.9132, 443.4128,  97.8970,  40.0742,  13.3184,  51.6890,
           7.5275,   4.9884,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 174.5152, 450.5650,  97.4934,  41.4621,  14.4961,  52.1031,
           9.8685,   4.5584,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 172.8722, 459.5829, 100.1892,  40.3760,  17.1490,  44.0406,
          10.6886,   5.6115,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 168.0271, 438.3856, 101.5193,  40.6333,  16.7866,  58.6419,
           7.6612,   5.2220,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 170.7820, 391.2906, 101.6617,  40.3823,  13.2645,  51.0499,
          10.1310,   4.8885,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   0.0000],
        [ 64.0000, 166.6331, 378.1541, 100.9956,  40.5358,  15.2015,  43.1286,
          11.6709,   4.9686,   0.0000,   1.0000,   1.0000,   0.0000,   0.0000,
           3.0000,  20.0000,   1.0000]])

    def __len__(self):
        return 1

    def __getitem__(self, index):
        return self.x

class MicrosoftTrainDataset(Dataset):
    def __init__(self, all_seqs, min_feature, max_feature):
        self.all_seqs = copy.deepcopy(all_seqs)
        self.processed_data, self.processed_label = self.preprocess(
            self.all_seqs, min_feature, max_feature
        )
        # pdb.set_trace()

    def preprocess(self, all_seqs, min_feature, max_feature):
        # for each sequence, correct all possible training data and labels
        # Note: max look back is 128 steps, encoder is unrolled 64 steps
        look_back_steps = 128
        unrolled_steps = 64
        features = []
        labels = []
        for one_seq in all_seqs:
            length = len(one_seq)
            for i in range(0, length - 1):
                lower_bound = max(0, i - look_back_steps)
                upper_bound = min(length, i + 1 + unrolled_steps)

                one_seq_array = np.array(one_seq)
                x = one_seq_array[lower_bound : i + 1][:, :-1]
                y = one_seq_array[i + 1 : upper_bound][:, -1]

                # perform min-max transformation
                x = 2 * (x - min_feature) / (max_feature - min_feature) - 1

                x = torch.from_numpy(x).float()
                y = torch.from_numpy(y).float()
                features.append(x)
                labels.append(y)

        return features, labels

    def __len__(self):
        return len(self.processed_data)

    def __getitem__(self, idx):
        x = self.processed_data[idx]
        length = len(x)
        y = self.processed_label[idx]
        # pdb.set_trace()
        return x, length, y


class MicrosoftTestDataset(Dataset):
    def __init__(self, all_seqs):
        self.all_seqs = copy.deepcopy(all_seqs)

    def __len__(self):
        return len(self.all_seqs)

    def __getitem__(self, idx):
        return self.all_seqs[idx]


def process_data(csv_file, split=[0.5, 0.2, 0.3]):
    raw_data = pd.read_csv(csv_file)

    data_copy = raw_data.copy()
    data_copy["model"] = data_copy["model"].apply(lambda x: float(x[5:]))
    data_copy["failure"] = data_copy["failure"].apply(lambda x: float(x))
    data_copy.drop(columns=["datetime"], inplace=True)
    # pdb.set_trace()
    data_array = data_copy.to_numpy(dtype=float)  # (58300, 17)

    max_feature = np.max(data_array, axis=0)[:-1]
    min_feature = np.min(data_array, axis=0)[:-1]

    data_array = data_array.reshape((100, 583, 17))

    # find each sequence that leads to failure
    all_seqs = []
    for i in range(0, 100):
        one_seq = []
        for j in range(0, 583):
            assert data_array[i][j][0] == i + 1  # check machine id

            if data_array[i][j][-1] == 0.0:
                # no failure, add to sequence
                one_seq.append(data_array[i][j])
            elif data_array[i][j][-1] == 1.0:
                # failure occurs, add if the sequence is no empty
                if len(one_seq) > 0:
                    one_seq.append(data_array[i][j])
                    all_seqs.append(one_seq)
                    one_seq = []
            else:
                assert False

    random.shuffle(all_seqs)
    sizes = np.array(split) * len(all_seqs)

    train_sz, valid_sz = math.floor(sizes[0]), math.floor(sizes[1])
    train_dataset = MicrosoftTrainDataset(
        all_seqs[0:1], min_feature, max_feature
    )
    print(all_seqs[0:1])
    pdb.set_trace()
    valid_dataset = MicrosoftTrainDataset(
        all_seqs[train_sz : train_sz + valid_sz], min_feature, max_feature
    )
    test_dataset = MicrosoftTestDataset(all_seqs[train_sz + valid_sz :])

    return train_dataset, valid_dataset, test_dataset


if __name__ == "__main__":
    process_data("../AMLWorkshop/Data/features_15h.csv")
    # MicrosoftTrainDataset("../AMLWorkshop/Data/features_15h.csv")
    # MicrosoftDataset("/Users/yuningwang/Desktop/CS535_final_project/AMLWorkshop/Data/features_15h.csv")
